\section{Results}
\paragraph{Modeling allele frequency trajectories in finite populations.} 
We first tested the goodness of fit the (discrete) Markov chain versus 
(continues) Brownian motion in modeling allele frequency trajectories in finite 
populations, under different sampling schemes and starting frequencies.
For this purpose, we conducted $150$K simulations with two time samples 
$\Tc=\{0,\tau\}$ where $\tau\in
\{1,10,100\}$ is the parameter controlling density of sampling in time.
In addition, we repeated simulations for different values of starting 
frequency  $\nu_0\in\{0.005,0.1\}$ (i.e., hard and soft sweep) and selection 
strength $s\in\{0,0.1\}$ 
(i.e., neutral and selection). Then, given initial frequency $\nu_0$, we 
computed expected distribution of the frequency of the next sample $\nu_\tau$ 
under two models and compared them with empirical distributions calculated from 
simulated data.
Fig.~\ref{fig:markov}A-F shows that Brownian motion (Gaussian approximation) is
inadequate when $\nu_0$ is far from $0.5$, and when sampling is done
after many generations $\tau>1$ (sampling times are sparse). If the favored 
allele raises from standing variation in a neutral population, it is unlikely 
to have frequency
close to $0.5$, and the starting frequencies are usually much
smaller (see Suppl. Fig.~\ref{fig:sfs}). Moreover, in typical
\dmel experiments for example, samples are taken sparsely, usually experiment 
is designed so that  
$10\le\tau\le100$~\cite{kofler2013guide, orozco2012adaptation, 
zhou2011experimental}.

In contrast, Fig.~\ref{fig:markov}A-I also shows that Markov
chain predictions (Eq.~\ref{eq:mkvs}) are highly consistent with
empirical data for a wide range of simulation parameters for both selection and 
neutral evolution.

\paragraph{Detection Power.} 
In this part we compare performance of methods in classifying a region as being 
under selection or not.
To evaluate performance of each method, define power as the 
(scaled) area under Receiver Operating Characteristic (ROC) curve restricted to 
the areas where false-positive rate $\le 0.05$ 
(Suppl.~Fig.~\ref{fig:powerROC}). Power take values between 0 and 100 and power 
of 5 represent prediction of a random hypothesis (diagonal line in ROC curves 
\AI{does it help?}). 
We also took into account of ascertainment bias in our comparisons, by 
evaluating each simulation for different coverages $\lambda\in 
\{30,100,\infty\}$. Depth of each variant identically and  independently from 
Poisson$(\lambda)$. 
To evaluate power for each configuration (specified with 
values for selection coefficient $s$, starting allele frequency
$\nu_0$ and coverage $\lambda$), we conducted $1000$ simulations, half of which
modeled neutral evolution and the rest modeled natural selection.

Before comparing against other methods, we first evaluated the use of \comale\ 
with different percentile-cutoffs $\pi$ (Eq.~\ref{eq:pihmm})
in computing composite statistics of a region. 
We also, evaluated 
performance for the \comale\ statistic computed using both standard and 
modified likelihood ratios, $\Hc(|H|)$ and $\Hc(H)$, respectively.
For each configuration, we computed average of powers for 
$s\in\{0.025,0.05,0.075,0.1\}$. 
Then, using a line search on $\pi$, we computed the best performance of each 
setting (corresponding to $\pi^*$). In all cases, $\pi^*$ achieved by $\Hc(H)$ 
(see Fig.~\ref{fig:clrq}).
Moreover, Fig.~\ref{fig:clrq} reveals several important trade-off between 
$\pi$, initial frequency and coverage.
First, in all the soft sweep cases (Fig.~\ref{fig:clrq}D-F), $\pi^*$ is higher 
than hard sweep cases (Fig.~\ref{fig:clrq}A-C). This implies that when 
favored allele has higher initial frequency, it 
is in lower LD with other sites and therefore it is beneficial to take higher 
values of $\pi$ to average over less candidate variants. For instance, in soft 
sweep with infinite coverage 
(Fig.~\ref{fig:clrq}F), optimum is gained at $\pi^*=100$, equivalent to taking 
maximum of the individual SNP likelihood scores in the window.
Second, $\pi^*$ is smaller when coverage is lower, i.e., taking average on more 
candidate SNPs boosts performance when sequencing coverage is low.
In the following, we use $\pi=0.95,0.98, 0.99$ for $\lambda=30,100,\infty$, 
respectively, and modified likelihood ratio $H$ to 
compute \comale\ statistics.

We also tested how does the $\Mc$ performs compared to $\Hc$,
if the allele frequency computed from read counts.
As shown in Fig.~\ref{fig:powerCLR}, the performance of
$\Hc$ is robust to change in coverage, while the power of
$\Mc$ decays for low coverage simulations.

Finally, we compared the power of \comale\ with Gaussian process
(GP)~\cite{Terhorst2015Multi}, FIT~\cite{feder2014Identifying}, and
CMH~\cite{agresti2011categorical} statistics. 
As CMH only takes read count data, here we used $\lambda=300$ to implement 
infinite coverage scenario. All methods other than \comale\ and CMH convert 
read counts to allele frequencies prior to computing the test statistic. 
\comale\ shows the highest power in all cases and it has the least decay as 
sequencing coverage decreased(Fig.~\ref{fig:power}). In particular, the 
difference in performance of \comale\ with other methods is pronounced when 
starting frequency is low (hard sweep). This stems from the fact low 
frequencies can note eve represented in low coverage. For example, when 
coverage is 30$\times$, the minimum allele frequency can be represented is 
0.033, and 
in many cases the favored allele does not even reach to this threshold. 
Nevertheless, unlike other method, \comale\ performs well when selection is 
strong enough (Fig.~\ref{fig:power}A-B). Moreover, the observation of 
Fig.~\ref{fig:markov} is revisited here, approximate continues models (GP and 
FIT) perform poorly when starting frequency is low (Fig.~\ref{fig:power}A-C).


\paragraph{SFS for Detection in Natural Samples.} We did not show the
SFS based statistics in Fig.~\ref{fig:power} as they did not perform
better than random. In many experimental evolution settings, we sample
a restricted set of $F$ founder lines, where $F<<N_e$
(Fig.~\ref{fig:ee}B) and inbred during the experiment. This creates a severe 
bottleneck, confounding
SFS. Suppl.~Fig.~\ref{fig:bottleneck} demonstrates the effect of
experimental evolution on different SFS statistics under neutral
evolution for 1000 simulations. A second problem with using SFS for
experimental evolution is that the sampling starts right after the
onset of experimentally induced selection, and the favored allele may
not reach high enough frequency to modify the site frequency spectrum
(Suppl. Fig.~\ref{fig:sweep}).

However, in experiments involving naturally occurring populations,
even if the span of the time-series is small, the onset of selection
might occur many generations prior to sampling. To test performance of
SFS-based statistics in natural evolution, we conducted 200 (100
neutral and 100 sweep) forward simulations for different values of
$s,\lambda$ using $N_e=10K$ and accumulating new mutations. The start
of sampling was done at a randomly picked time subsequent to the onset
of selection in two distinct scenarios. Let $t_{\nu=x}(s,N_e)$ denote
the expected time (in generations) required to reach carrier frequency
$x$ in a hard sweep and $U[a,b]$ denote discrete uniform distribution
in the interval $[a,b]$. First we considered the case when start of
sampling is chosen throughout the whole sweep. i.e., $\tau_1 \sim
U\left[1,t_{\nu=1}(s,N_e)\right]$ (Fig.~\ref{fig:powerSFS}A). Next, we
considered sampling start time chosen nearer to fixation of the
favored allele, i.e., $\tau_1 \sim
U\left[t_{\nu=0.9}(s,N_e),t_{\nu=1}(s,N_e)\right]$
(Fig.~\ref{fig:powerSFS}B). In both scenarios, sampling was done over
$5$ time points within $50$ generations of $\tau_1$. We compared
$\Hc$, GP, FIT with both static and dynamic SFS based statistics of
SFSelect and Tajima's D. Fig.~\ref{fig:powerSFS}A shows that SFS based
statistics are outperformed by single locus and CLR methods. However,
when sampling is performed close to fixation, i.e., when the favored
allele has frequency of 0.9 or higher, SFS based statistics perform
significantly better than GP, FIT and $\Hc$
(Fig.~\ref{fig:powerSFS}b). Moreover, dynamic SFS statistics
outperform static SFS statistics, demonstrating that in these regimes,
SFS based statistics could be used to detect selection.


\paragraph{Site-localization.}
Localizing adaptive allele is a nontrivial task, and here we only aim to find 
candidate variants (see Sec.~\ref{sec:method}). 
To identify the favored site, we simply ranked each site in the
detected window according to the likelihood ratio scores
(Eqns.~\ref{eq:mcts},~\ref{eq:hmmml}). For each setting of $\nu_0$ and $s$, 
we conducted 500 simulations and computed the rank of the favored 
mutation in each
simulation. 
We plotted the cumulative distribution of the rank of the favored allele in 500 
simulation for each setting (Fig.~\ref{fig:rank}) to show that \comale\ 
outperforms other statistics. 
When only restricting to top of the rankings, in more simulations \comale\ 
ranked the favored allele in top 1, 10 and 50 
(Table~\ref{tab:rank}A-B, Table~\ref{tab:rank}C-D and Table~\ref{tab:rank}E-F, 
respectively) the ranking of approximately 1150 variants, than other methods. 

An interesting observation is the contrasting results
between site-localization and detection in hard and soft sweep.
Specifically, while stronger selection always helps to detect presence of 
selection (Fig.~\ref{fig:power}A-F), it makes site-localization harder and 
easier for hard and soft sweep, respectively (Table~\ref{tab:rank}A-F).
For example, when coverage is 100 and $s=0.1$, detection power is 80 and 100 
for hard and soft sweep (Fig.~\ref{fig:power}B-E), but is in 14 and 95 percent 
for hard and soft sweep (Table~\ref{tab:rank}A-B).
This observation is consistent with the discussion on dynamic of LD after 
selection (Appendix~\ref{app:ld}) and previous 
studies~\cite{long2013massive,tobler2014massive}.
 
\paragraph{Estimating Parameters.}
As the \comale\ likelihood calculation is model based, \comale\
computes the selection parameters $\hat{s}$ and $\hat{h}$ as a byproduct of the 
hypothesis testing. We computed bias of selection fitness ($s-\hat{s}$) and 
over dominance ($h-\hat{h}$) for of \comale\ and GP in each setting. The 
distribution of
the error (bias) for 100$\times$ coverage is presented in
Fig.~\ref{fig:bias100} for different configurations.
Suppl.~Fig.~\ref{fig:bias30},~\ref{fig:biasinf}
provide the distribution of estimation errors for 30$\times$, and infinite 
coverage, respectively.  In hard sweeps (Fig.\ref{fig:bias100}A), \comale\ 
provide slightly better estimates of $s$, in the sense that its variance of 
bias is lower. In soft sweep, they both provide unbiased estimates with low 
variance (Fig.~\ref{fig:bias100}B).
Also Fig.~\ref{fig:bias100}C-D shows that \comale\ provides unbiased estimates 
of $h$.

\paragraph{Running Time.}
As \comale\ does not compute exact likelihood of a region (i.e., does not 
explicitly model linkage between sites), the complexity of scanning a genome is 
linear in number of polymorphisms.
Calculating score of each polymorphism require
$\Oc(TR)$ and $\Oc(TRN^2)$ computation for \comale-M and \comale-M, 
respectively. However, most of the operations are ``embarrassingly parallel" 
and can be vectorized to be run in $\Oc(T)$ and $\Oc(TN)$ for each variant.
Therefore, it is expected to be faster than full-likelihood
approaches like Gaussian Process (GP)~\cite{Terhorst2015Multi}. We
conducted $1000$ simulations and measured running times for \comale-M, 
\comale-H, FIT, CMH and GP with different number of linked-loci. 
Our analysis reveals (Fig.~\ref{fig:runTime}) that \comale\ is orders of 
magnitude faster than GP, and its run time comparable to CMH (which is a 
two-time point test) and FIT (which is a neutrality test), while maintaining 
higher detection, localization and estimation power. 

These times can have a practical consequence. For instance, to run GP in the 
single locus mode on
the entire pool-seqed \dmel genome of a small sample (1.5M variant
sites), it would take 1444 CPU-hours ($\approx$ 1 CPU-month). In
contrast, after vectorizing and broadcasting operations for all variants 
operations using \texttt{numba} package, \comale\ takes less than an hour to 
perform an scan, including precomputation.

\subsection{Analysis of the real data}\label{sec:dmel}
We applied \comale\ to the \data~\cite{orozco2012adaptation}, where 3 
replicate samples
were chosen from a population of \dmel for 59
generations under alternating 12-hour cycles of hot (28$^{\circ}$C)
and cold (18$^{\circ}$C) temperatures and sequenced. 
In this dataset, sequencing coverage is different across replicates and 
generations (see Fig. S2 of~\cite{Terhorst2015Multi}) which makes variant 
depths highly heterogeneous (Suppl. 
Figs.~~\ref{fig:depth},~\ref{fig:depthHetero}). Filtering low
coverage sites from data can dramatically reduce data available for
analysis. For example, by setting minimum read depth at a site to be
$30$, allowing the site to be retained only if the depth for all time
points, and all replicates exceeded $30$, the number of sites analyzed
would drop from from 1,544,374 to 10,387. The \comale\ $\Hc$ statistic
automatically handles such a heterogeneity in HMM (see 
Fig.~\ref{fig:stateConditional}). We computed the ${\cal H}$ statistic for 
sliding window of 50Kbp with steps
of 10Kbp over the whole genome. We filtered out genomic regions
containing fewer than $500$ SNPs, as those regions were close to the
centromere or telomere. Fig.~\ref{fig:manhattancutoffed} shows a
Manhattan plot of scores. Our results are consistent with previous
studies in showing an over-representation
of significant variants on Chromosome 3R~\cite{orozco2012adaptation} and 
identifying intervals under selection~\cite{Terhorst2015Multi}.

The 1\%-ile cut-off (dashed line in Fig.~\ref{fig:manhattancutoffed})
reveals $21$ distinct intervals (Table~\ref{tab:intervals}) spanning
$243$ of the $13,965$ genes that encoded variants. We found $36$ GO
terms associated with ``Biological Process'' to be over-represented in
the $243$ genes using the Fisher exact test for
significance. Table~\ref{tab:Fisher} describes all $13$ terms that
were significant and contained at least $3$ genes. The effect of high
temperature on metabolism is profound, and it is not surprising that
the enriched GO terms include many generic stress and stress response
genes. They also include $5$ of $7$ genes with aminoacylase activity,
and $4$ of $17$ genes involved in peroxidase activity. Stress induced
formation of reactive oxygen species (ROS) can have deleterious
effects, and peroxidase activity has been seen in other organisms. In
many plants, including strawberry, high temperature adaptation led to
an increase in expression of ROS scavenging genes, including
peroxidase, and a reduction in total protein content due to protein
denaturation, and inhibited synthesis~\cite{gulen2004effect}, and
these effects are also observed in potato. The genes include Pxd
(CG3477), the peroxidase component of the
chorion~\cite{konstandi2005enzymatic}. Chorion peroxidases are
conjectured to play a role in ROS defense during egg formation in
mosquitoes~\cite{li2006major}.


One of the difficulties in genome-wide association studies is that the
number of polymorphisms are different between genes, i.e., longer
genes contain more SNPs and larger number of polymorphisms increase
the chance of showing association for larger genes.  Although the
\comale\ statistic for genes does not favor longer genes, we performed
SNP-based GO enrichment and compared enrichment versus the window
based approach. We tested associations of top 1\%-ile of the SNPs
within the $21$ candidate intervals (Table~\ref{tab:intervals}) using
\texttt{Gowinda}~\cite{kofler2012gowinda} and found 325 GO terms (see
supplemental table S4) with FDR $\le 0.001$. $9$ of the $13$
previously enriched terms (Table~\ref{tab:Fisher}), overlapped with
the $325$ \texttt{Gowinda} terms (Fisher exact $p$-val: $10^{-11}$)
suggesting consistency of SNP based and window-based analysis.
