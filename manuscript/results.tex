\section{Results}
\paragraph{Modeling Allele Frequency Trajectories in Finite Populations.} 
We first tested the goodness of fit of the discrete-time Markov chain
versus continuous-time Brownian motion (Gaussian approximation) in modeling 
allele frequency
trajectories in finite populations, under different sampling schemes
and starting frequencies.  For this purpose, we conducted $100$K
simulations with two time samples $\Tc=\{0,\tau\}$ where $\tau\in
\{1,10,100\}$ is the parameter controlling the density of sampling
in time.  In addition, we repeated simulations for different values of
starting frequency $\nu_0\in\{0.005,0.1\}$ (i.e., hard and soft sweep)
and selection strength $s\in\{0,0.1\}$ (i.e., neutral and
selection). Then, given initial frequency $\nu_0$, we computed
expected distribution of the frequency of the next sample $\nu_\tau$
under two models and compared them with empirical distributions
calculated from simulated data.  Fig.~\ref{fig:markov}A-F shows that
Brownian motion is inadequate when $\nu_0$ is
far from $0.5$, or when sampling times are sparse ($\tau>1$). If the
favored allele arises from standing variation in a neutral population,
it is unlikely to have frequency close to $0.5$, and the starting
frequencies are usually much smaller (see
Suppl. Fig.~\ref{fig:sfs}). Moreover, in typical \dmel experiments for
example, sampling is sparse. Often, the experiment is designed so that
$10\le\tau\le100$~\cite{kofler2013guide, orozco2012adaptation,
  zhou2011experimental}.

In contrast to the Brownian motion results,  Markov chain can provide 
predictions when the the allele is under selection. In addition 
Fig.~\ref{fig:markov}A-M
also shows that Markov chain predictions (Eq.~\ref{eq:mkvs}) are
highly consistent with empirical data for a wide range of simulation
parameters.

\paragraph{Detection Power.} 
We compared the performance of \comale\ against other methods for
detecting selection. For each method we calculated detection power as the 
percentage of true-positives identified with false-positive rate $\le 0.05$
(Suppl.~Fig.~\ref{fig:powerROC}). For each
configuration (specified with values for selection coefficient $s$,
starting allele frequency $\nu_0$ and coverage $\lambda$), power of each method 
is evaluated over $2000$ distinct simulations, half of which modeled neutral 
evolution
and the rest modeled positive selection.

Before comparing against other methods, we first evaluated the use of
\comale\ with different percentile-cutoffs $\pi$ (Eq.~\ref{eq:pihmm})
in computing composite statistics of a region. For each configuration,
we computed average Power for $s\in\{0.025,0.05,0.075,0.1\}$, using
$\Hc_\pi,\Hc^{+}_\pi$. We computed the optimal value of $\pi$ using a
line-search. Fig.~\ref{fig:clrq} reveals several important trade-off
between $\pi$, initial frequency, and coverage.
\begin{packed_itemize}
\item $\Hc^{+}_\pi$ consistently achieves a high power for $\pi=0$,
  and in the absence of knowledge of the selection regime or the
  ancestral allele, $\Hc^{+}_0$ is a powerful statistic to use.
\item In every scenario tested,
  $\max_{\pi}\{\mbox{Power}(\Hc_\pi)\}\ge
  \max_{\pi}\{\mbox{Power}(\Hc^{+}_\pi)\}$, suggesting that it is beneficial to 
  make predictions based on $\Hc_{\pi}$, if the
  selection regime is well-understood and ancestral allele is known.
\item In soft sweep, relative to hard sweep, it helps to choose a
  higher value of the cut-off $\pi$. This is consistent with the fact that LD
  between the favored site and other sites is generally lower for
  soft sweep. For instance, in soft sweep with infinite coverage
  (Fig.~\ref{fig:clrq}F), optimum is gained at $\pi=100$, equivalent
  to considering the score of the highest scoring site as $\Hc$ statistic of 
  the region.
\item When coverage is low (Fig.~\ref{fig:clrq}A,D), it helps to
  accumulate evidence from multiple sites, and the best results are
  achieved for lower values of $\pi$.
\end{packed_itemize}
In the following tests, we fix the value of $\pi=70,97, 99$ for
$\lambda=30,100,300$, respectively, and simplify notation by
denoting the optimum score as $\Hc$. For example, when $\lambda=30$,
$\Hc$ corresponds to $\Hc_{70}$. In addition, we use $\Hc^{+}$ to
denote $\Hc^{+}_0$. We also compared $\Mc$ (Markov likelihoods) versus
$\Hc$. As shown in Fig.~\ref{fig:powerCLR}, $\Hc$ has better power for
low coverage ($\lambda=30$) compared to $\Mc$ decays.


\ignore{
, and modified likelihood ratio
$H$ to compute \comale\ statistics.
}

Finally, we compared the power of \comale\ with Gaussian process
(GP)~\cite{Terhorst2015Multi}, FIT~\cite{feder2014Identifying}, and
CMH~\cite{agresti2011categorical} statistics.  As CMH only takes read
count data, here we used $\lambda=300$ to implement infinite coverage
scenario. All methods other than \comale\ and CMH convert read counts
to allele frequencies prior to computing the test statistic.  \comale\
shows the highest power in all cases and the power stays relatively
high even for low coverage (Fig.~\ref{fig:power} and
Table~\ref{tab:power}). In particular, the difference in performance
of \comale\ with other methods is pronounced when starting frequency
is low. Starting frequency is at its minimum in selection on an allele
from \emph{de novo} mutations and is likely to be low if selection is
on an allele from standing variation (Suppl. Fig.~\ref{fig:sfs}).  The
advantage of \comale\ stems from the fact that favored allele with low
starting frequency might be missed by low coverage sequencing. In this
case, incorporating the signal from linked sites becomes increasingly
important. We note that methods using only two time points, such as
CMH, do relatively well for high selection values and high
coverage. However, the use of time-series data can increase detection
power in low coverage experiments or when starting frequency is
low. Moreover, time-series data provide means for estimating selection
parameters $s,h$ (see below). Finally, as \comale\ is robust to change
of coverage, our results (Fig.~\ref{fig:power}B,C) suggest that taking
many samples with lower coverage is preferable to sparse sampling with
higher coverage.


\ignore{ Moreover, the observation of
  Fig.~\ref{fig:markov} is revisited here, approximate continues
  models (GP and FIT) perform poorly when starting frequency is low
  (Fig.~\ref{fig:power}A-C).  }

\paragraph{SFS for Detection in Natural Samples.} We did not show the
SFS based statistics in Fig.~\ref{fig:power} as they did not perform
better than random. In majority of controlled experimental evolution studies, 
the population is restricted set of $F$ founder lines, where $F<<N_e$
(Fig.~\ref{fig:ee}B) and inbred during the experiment. This creates a severe 
bottleneck, confounding
SFS. Suppl.~Fig.~\ref{fig:bottleneck} demonstrates the effect of
experimental evolution on different SFS statistics under neutral
evolution for 1000 simulations. A second problem with using SFS for
experimental evolution is that the sampling starts right after the
onset of experimentally induced selection, and the favored allele may
not reach high enough frequency to modify the site frequency spectrum
(Suppl. Fig.~\ref{fig:sweep}).

However, in experiments involving naturally evolving populations,
even if the span of the time-series is small, the onset of selection
might occur many generations prior to sampling. To test performance of
SFS-based statistics in natural evolution, using \texttt{msms}, we conducted 
200 (100
neutral and 100 sweep) forward simulations for different values of
$s$, $N_e=10K$ and $N=200$. The start
of sampling was chosen randomly after onset of selection in two distinct 
scenarios. Let $t_{\nu=x}(s,N_e)$ denote
the expected time (in generations) required to reach carrier frequency
$x$ in a hard sweep and $U[a,b]$ denote discrete uniform distribution
in the interval $[a,b]$. First we considered the case when start of
sampling is chosen throughout the whole sweep. i.e., $\tau_0 \sim
U\left[1,t_{\nu=1}(s,N_e)\right]$ (Fig.~\ref{fig:powerSFS}A). Next, we
considered sampling start time chosen nearer to fixation of the
favored allele, i.e., $\tau_0 \sim
U\left[t_{\nu=0.9}(s,N_e),t_{\nu=1}(s,N_e)\right]$
(Fig.~\ref{fig:powerSFS}B). In both scenarios, sampling was done over
$6$ time points within $50$ generations of $\tau_0$ (Fig.~\ref{fig:ee}A). We 
compared
\comale, GP, FIT with both static and dynamic SFS based statistics of
SFSelect and Tajima's D. Fig.~\ref{fig:powerSFS}A shows that SFS based
statistics are outperformed by other methods. However,
when sampling is performed close to fixation, i.e., when the favored
allele has frequency of 0.9 or higher, SFS based statistics perform
considerably better than GP, FIT and \comale\
(Fig.~\ref{fig:powerSFS}b). Moreover, dynamic SFS statistics
provide higher power than static SFS statistics, demonstrating that in the use 
of time-series SFS based statistics is advantageous.


\paragraph{Site-identification.}
In general, localizing the favored variant, using pool-seq data is a nontrivial 
task~\cite{tobler2014massive}. We used the simple
approach of ranking each site in a region detected as being under
selection. The sites were ranked according to the likelihood ratio
scores (Eqns.~\ref{eq:mcts},~\ref{eq:hmmml}). For each setting of
$\nu_0$ and $s$, we conducted $1000$ simulations and computed the rank
of the favored mutation in each simulation. The cumulative
distribution of the rank of the favored allele in 1000 simulation for
each setting (Fig.~\ref{fig:rank}) shows that \comale\ outperforms
other statistics. We also compared each method to see how often it
ranked the favored site in as the top ranked site
(Table~\ref{tab:rank}A-B), among the top 10 ranked sites
(Table~\ref{tab:rank}C-D), and among the top 50
(Table~\ref{tab:rank}E-F) ranked sites. In the $\approx$1150 variants tested,
\comale\ performed consistently better than other methods in all of
these measures.

An interesting observation is revisiting the contrast between 
site-identification
and detection~\cite{long2013massive,tobler2014massive} (Appendix~\ref{app:ld}). 
When selection 
coefficient is high, detection is easier
(Fig.~\ref{fig:power}A-F), but site-identification is harder due to
the high LD between hitchhiking sites and the favored allele
(Table~\ref{tab:rank}A-F).  Moreover, site-identification is harder in
hard sweep scenarios relative to soft sweeps. For example, when
coverage $\lambda=100$ and selection coefficient $s=0.1$, the
detection power is 75\% for hard sweep, but 100\% for soft sweep
(Fig.~\ref{fig:power}B-E). In contrast, the favored site was ranked as
the top in 14\% of hard sweep cases, compared to and 95\% of soft
sweep simulations (Table~\ref{tab:rank}A-B).  

\newcommand*\rot{\rotatebox{-90} }
\begin{table}[H]
	\centering
	\begin{tabular}{c||c}
		 Hard Sweep &Soft Sweep\\
		\hline
		(A) & (B)  \\
		{\input{../tables/top1.100.0.hard.tex}}
		 &{\input{../tables/top1.100.0.soft.tex} }\\
		\hline
		(C)  & (D)  \\
		{\input{../tables/top10.100.0.hard.tex}}
		& {\input{../tables/top10.100.0.soft.tex} }\\
		\hline
		(E) & (F) \\
		{\input{../tables/top50.100.0.hard.tex}}
		&{\input{../tables/top50.100.0.soft.tex} }\\
		\hline
	\end{tabular}\\
	\caption{{\bf Percentage of simulations which favored allele appears in top 
	of the ranking.}\\
		Percentage of simulations in which the favored allele is ranked 
	first 
		(A-B); 
		appears in top 10 (C-D); or,  appears in top 50 (E-F). In soft sweep 
		simulations (B,D,F), the ranks are consistently better than 
		hard sweep simulations (A,C,E). This can be attributed to lower LD 
		between the 
		hitchhikers (false positives) and favored allele in soft sweep 
		scenarios.}\label{tab:rank}
\end{table}
 
\paragraph{Estimating Parameters.}
\comale\ computes the selection parameters $\hat{s}$ and $\hat{h}$ as
a byproduct of the hypothesis testing. We computed bias of selection
fitness ($s-\hat{s}$) and overdominance ($h-\hat{h}$) for of \comale\
and GP in each setting. The distribution of the error (bias) for
100$\times$ coverage is presented in Fig.~\ref{fig:bias100} for
different configurations.
Suppl.~Fig.~\ref{fig:bias30},~\ref{fig:biasinf} provide the
distribution of estimation errors for 30$\times$, and infinite
coverage, respectively.  For hard sweep, \comale\ provides estimates
of $s$ with lower variance of bias (Fig.\ref{fig:bias100}A). In soft
sweep, GP and \comale\ both provide unbiased estimates with low
variance (Fig.~\ref{fig:bias100}B). Fig.~\ref{fig:bias100}C-D shows
that \comale\ provides unbiased estimates of $h$ as well.

\paragraph{Running Time.}
As \comale\ does not compute exact likelihood of a region (i.e., does
not explicitly model linkage between sites), the complexity of
scanning a genome is linear in number of polymorphisms.  Calculating
score of each variant requires $\Oc(TR)$ and $\Oc(TRN^2)$ computation
for $\Mc$, and $\Hc$, respectively. However, most of the operations
are can be vectorized for all replicates to make the effective running
time for each variant.  We
conducted $1000$ simulations and measured running times for computing site 
statistics $M$, $H$, FIT, CMH and GP with different number of linked-loci.  Our
analysis reveals (Fig.~\ref{fig:runTime}) that \comale\ is orders of
magnitude faster than GP, and comparable to FIT. While slower than CMH
on the time per variant, the actual running times are comparable after
vectorization and broadcasting over variants (see below).

These times can have a practical consequence. For instance, to run GP
in the single locus mode on the entire pool-seq data of the \dmel genome from a
small sample ($\approx$1.6M variant sites), it would take 1444 CPU-hours
($\approx$ 1 CPU-month). In contrast, after vectorizing and
broadcasting operations for all variants operations using
\texttt{numba} package, \comale\ took 75 minutes to perform an
scan, including precomputation, while the fastest method, CMH, took 17 minutes.

\subsection{Analysis of a \dmel Adaptation to Cold and Hot 
Temperatures}\label{sec:dmel}
We applied \comale\ to the \datadm~\cite{orozco2012adaptation}, where
3 replicate samples were chosen from a population of \dmel for 59
generations under alternating 12-hour cycles of hot (28$^{\circ}$C)
and cold (18$^{\circ}$C) temperatures and sequenced.  In this dataset,
sequencing coverage is different across replicates and generations
(see Fig. S2 of~\cite{Terhorst2015Multi}) which makes variant depths
highly heterogeneous (Suppl.
Figs.~\ref{fig:depth},~\ref{fig:depthHetero}). We computed the
$\Hc^{+}$ statistic for sliding windows of 30Kbp with steps of 10Kbp
over the whole genome. After filtering out heterochromatic,
centromeric and telomeric
regions\cite{fiston2010drosophila,comeron2012many}, and applying a
local false discovery rate $\le 0.01$ (Methods), we identified 89
intervals (Fig.~\ref{fig:manhattancutoffed}) containing 968 genes
(Suppl. Table~\ref{tab:stats}).

We found $11$ GO Biological Process terms to be enriched with Fisher
exact $P$-value $\le 10^{-3}$ (Table~\ref{tab:Fisher2}). The selected
genes include many heat shock proteins in enriched ontologies
including `cold acclimation' and `response to heat'
(Table~\ref{tab:tempGenes}). As longer genes contain more variants,
the probability of a false variant being selected could increase with
the length of the gene. Although the \comale\ statistic for genes does
not favor longer genes, we also performed a single variant based GO
enrichment using \texttt{Gowinda}~\cite{kofler2012gowinda}. The
analysis identified 34 enriched GO terms
(Suppl. Table~\ref{tab:gowinda}) associated with Biological Process. 5
of 11 GO terms in the gene level analysis were also among the $34$
\texttt{Gowinda} terms (Fisher exact $p$-val: $10^{-8}$) suggesting
consistency between variant and gene-based analysis.

\begin{table}[H]
	\begin{tabular}{c}
		\input{../tables/biological_process.tex}
	\end{tabular}
	\caption{{\bf GO (Biological Process) enrichment.}\\ A Fisher exact test 
	was 
	performed for GO enrichment in genes located in selected regions. All GO 
	terms that contained at least $3$ selected genes, and had Fisher exact 
	$p$-value $\le 10^{-3}$, are listed above.}\label{tab:Fisher2}
\end{table}